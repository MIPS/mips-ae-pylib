{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec330c2",
   "metadata": {},
   "source": [
    "# ATLAS Explorer: Single-Core Experiment\n",
    "\n",
    "Welcome! This guided notebook walks you through running a *single-core* ATLAS Explorer experiment.\n",
    "\n",
    "You will:\n",
    "1. Verify prerequisites\n",
    "2. Configure (or auto-detect) your credentials\n",
    "3. Set a few experiment parameters (file, core type, etc.)\n",
    "4. Run the experiment\n",
    "5. View key results (Total Cycles + summary table)\n",
    "6. (Optional) Explore derived metrics\n",
    "\n",
    "Tips:\n",
    "- Edit only the clearly marked parameter cells (grey code boxes with simple assignments)\n",
    "- Re‚Äërun a cell with Shift+Enter\n",
    "- If something fails, read the printed message and adjust the parameters\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment initialized. Proceed to the next cell.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "üöÄ ATLAS Explorer Single-Core Analysis - Getting Started\n",
    "\n",
    "Welcome to ATLAS Explorer! This notebook is your step-by-step guide to running \n",
    "performance analysis on single-core processor workloads.\n",
    "\n",
    "What you'll learn:\n",
    "‚Ä¢ How to set up and configure ATLAS Explorer\n",
    "‚Ä¢ Running performance experiments on CPU cores\n",
    "‚Ä¢ Analyzing key metrics like cycles, instructions, and IPC\n",
    "‚Ä¢ Understanding bottlenecks and optimization opportunities\n",
    "\n",
    "üí° Beginner Tips:\n",
    "- Green text = successful operations\n",
    "- Red text = errors (read carefully for solutions)  \n",
    "- Each cell builds on the previous one - run them in order\n",
    "- Don't worry about the code details - focus on the results!\n",
    "\n",
    "Let's start by importing the necessary libraries...\n",
    "\"\"\"\n",
    "import os, json, locale, datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd  # used for tabular display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load any .env for convenience (optional)\n",
    "load_dotenv()\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "\n",
    "print(\"‚úÖ Environment initialized successfully!\")\n",
    "print(\"üìù Next step: Run the next cell to check your project setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a52ac6a",
   "metadata": {},
   "source": [
    "## 1. Check Project & Existing Experiments\n",
    "\n",
    "üìÅ **What this does:** Ensures you're in the right directory and shows any previous experiment results.\n",
    "\n",
    "This cell will:\n",
    "- Automatically find your project root directory \n",
    "- List any prior experiment runs stored in `myexperiments/` folder\n",
    "- Show you when each experiment was last modified\n",
    "\n",
    "**For beginners:** Think of this as checking your workspace - like opening the right folder before starting work. If you see previous experiments listed, that's normal and helpful for reference!\n",
    "\n",
    "‚ú® **Just click \"Run\" below - no editing needed!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ab2bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to repo root: /Users/jschroeder/Documents/code_repos/mips-ae-pylib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I8500_(2_threads)_250808_103012</td>\n",
       "      <td>/Users/jschroeder/Documents/code_repos/mips-ae...</td>\n",
       "      <td>2025-08-08T10:34:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I8500_(1_thread)_250808_102301</td>\n",
       "      <td>/Users/jschroeder/Documents/code_repos/mips-ae...</td>\n",
       "      <td>2025-08-08T10:27:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  \\\n",
       "1  I8500_(2_threads)_250808_103012   \n",
       "0   I8500_(1_thread)_250808_102301   \n",
       "\n",
       "                                             summary             modified  \n",
       "1  /Users/jschroeder/Documents/code_repos/mips-ae...  2025-08-08T10:34:36  \n",
       "0  /Users/jschroeder/Documents/code_repos/mips-ae...  2025-08-08T10:27:58  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (No edits needed) Detect repo root and list existing experiment runs.\n",
    "from pathlib import Path\n",
    "import os, datetime\n",
    "\n",
    "cwd = Path.cwd()\n",
    "repo_root = None\n",
    "for p in [cwd, *cwd.parents]:\n",
    "    if (p / \"pyproject.toml\").exists() or (p / \".git\").exists():\n",
    "        repo_root = p\n",
    "        break\n",
    "repo_root = repo_root or cwd\n",
    "os.chdir(repo_root)\n",
    "print(f\"Working directory set to repo root: {repo_root}\")\n",
    "\n",
    "exp_root = repo_root / \"myexperiments\"\n",
    "rows = []\n",
    "if exp_root.exists():\n",
    "    for run_dir in sorted(exp_root.iterdir()):\n",
    "        if run_dir.is_dir():\n",
    "            summary = next(run_dir.rglob(\"reports/summary/summary.json\"), None)\n",
    "            mtime = datetime.datetime.fromtimestamp(run_dir.stat().st_mtime)\n",
    "            rows.append({\n",
    "                \"name\": run_dir.name,\n",
    "                \"summary\": str(summary) if summary else \"-\",\n",
    "                \"modified\": mtime.isoformat(timespec=\"seconds\"),\n",
    "            })\n",
    "    if not rows:\n",
    "        print(\"No experiments found yet under 'myexperiments'.\")\n",
    "else:\n",
    "    print(\"No 'myexperiments' directory found yet.\")\n",
    "\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows).sort_values(\"modified\", ascending=False)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0620e70d",
   "metadata": {},
   "source": [
    "## Project root & experiments\n",
    "This notebook will first switch the working directory to the repository root and list any existing experiments under `myexperiments/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c91c223",
   "metadata": {},
   "source": [
    "## 2. Configure Credentials\n",
    "\n",
    "üîê **What this does:** Sets up your connection to ATLAS Explorer's cloud services.\n",
    "\n",
    "**Think of this like logging into your account.** ATLAS Explorer needs three pieces of information:\n",
    "- **API Key:** Your unique identifier (like a password)\n",
    "- **Channel:** Which environment to use (usually \"development\" for testing)\n",
    "- **Region:** Which data center to connect to (e.g., \"us-west-2\")\n",
    "\n",
    "The system will automatically look for your credentials in two places:\n",
    "1. Environment variable `MIPS_ATLAS_CONFIG` (format: apikey:channel:region)  \n",
    "2. Config file at `~/.config/mips/atlaspy/config.json`\n",
    "\n",
    "**For beginners:** If this is your first time, you'll need to enter your credentials when prompted. Don't worry - the system will guide you through it and can save them for next time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa86f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials detected from environment variable MIPS_ATLAS_CONFIG.\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# üîê CREDENTIAL SETUP - Run this cell first, then follow the instructions\n",
    "from pathlib import Path\n",
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "CONFIG_ENV = \"MIPS_ATLAS_CONFIG\"\n",
    "cfg_file = Path.home() / \".config/mips/atlaspy/config.json\"\n",
    "\n",
    "print(\"üîç Checking for existing credentials...\")\n",
    "\n",
    "if os.environ.get(CONFIG_ENV):\n",
    "    print(\"‚úÖ Credentials detected from environment variable MIPS_ATLAS_CONFIG.\")\n",
    "elif cfg_file.exists():\n",
    "    try:\n",
    "        data = json.loads(cfg_file.read_text())\n",
    "        os.environ[CONFIG_ENV] = f\"{data['apikey']}:{data['channel']}:{data['region']}\"\n",
    "        print(f\"‚úÖ Credentials loaded from {cfg_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not parse {cfg_file}: {e}\")\n",
    "\n",
    "if not os.environ.get(CONFIG_ENV):\n",
    "    print(\"\\nüîë NO CREDENTIALS FOUND\")\n",
    "    print(\"üëá PLEASE FILL IN YOUR CREDENTIALS BELOW, then re-run this cell:\")\n",
    "    print(\"   (Ask your system administrator if you don't have these)\")\n",
    "    \n",
    "    # üìù EDIT THESE VALUES - Replace the empty strings with your actual credentials\n",
    "    ae_apikey   = \"\"  # ‚Üê PUT YOUR API KEY HERE (between the quotes)\n",
    "    ae_channel  = \"development\"  # ‚Üê Usually keep as \"development\" for testing\n",
    "    ae_region   = \"\"  # ‚Üê PUT YOUR REGION HERE (e.g., \"us-west-2\")\n",
    "    persist_to_file = True  # ‚Üê Set to False if you don't want to save credentials\n",
    "\n",
    "    if not ae_apikey or not ae_channel or not ae_region:\n",
    "        print(\"\\n‚è≥ Waiting for your input...\")\n",
    "        print(\"üí° Fill in ae_apikey, ae_channel, and ae_region above, then run this cell again\")\n",
    "    else:\n",
    "        os.environ[CONFIG_ENV] = f\"{ae_apikey}:{ae_channel}:{ae_region}\"\n",
    "        print(\"‚úÖ Session credentials set successfully!\")\n",
    "        if persist_to_file:\n",
    "            cfg_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            cfg_file.write_text(json.dumps({\"apikey\": ae_apikey, \"channel\": ae_channel, \"region\": ae_region}, indent=2))\n",
    "            print(f\"üíæ Credentials saved to {cfg_file} for future use\")\n",
    "else:\n",
    "    print(\"‚úÖ Ready to proceed with experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f992fae",
   "metadata": {},
   "source": [
    "## 3. Experiment Overview\n",
    "\n",
    "üß™ **What we're doing:** Running a performance analysis on a single CPU core with a test program.\n",
    "\n",
    "**In simple terms:** We'll take a small program (called an \"ELF file\") and run it on a virtual CPU core to see how it performs. This is like having a high-tech stopwatch that measures not just time, but also:\n",
    "\n",
    "- **Cycles:** How many clock ticks the program took\n",
    "- **Instructions:** How many individual operations were executed  \n",
    "- **IPC (Instructions Per Cycle):** How efficiently the CPU worked\n",
    "- **Memory usage:** How the program used cache and RAM\n",
    "- **Bottlenecks:** Where the program might be slowing down\n",
    "\n",
    "**For beginners:** Think of this like a diagnostic test for your program - we're measuring its \"vital signs\" to understand how healthy and efficient it is!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b31519",
   "metadata": {},
   "source": [
    "### Prerequisites Checklist ‚úÖ\n",
    "\n",
    "Before running your experiment, make sure you have:\n",
    "\n",
    "- ‚úÖ **Credentials configured** (completed in step 2 above)\n",
    "- ‚úÖ **Test program available** (we provide a sample program called `mandelbrot_rv64_O0.elf`)\n",
    "- ‚úÖ **Core configuration chosen** (we'll use a standard I8500 single-threaded core)\n",
    "\n",
    "**For beginners:** The default settings are perfect for your first experiment! The sample program we're using generates a mathematical pattern called a Mandelbrot set - it's computationally intensive, making it perfect for performance testing.\n",
    "\n",
    "**Advanced users:** Feel free to substitute your own ELF files or try different core configurations in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f128e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters set. Modify above as needed.\n"
     ]
    }
   ],
   "source": [
    "# üéõÔ∏è EXPERIMENT PARAMETERS - Beginners can use defaults, advanced users can customize\n",
    "\n",
    "print(\"‚öôÔ∏è Setting up experiment parameters...\")\n",
    "print(\"üí° Beginners: The default values below are perfect for your first run!\")\n",
    "print(\"üîß Advanced: Feel free to modify any of these parameters\\n\")\n",
    "\n",
    "# üìÅ WORKLOAD: Which program to analyze\n",
    "elf = \"resources/mandelbrot_rv64_O0.elf\"   # Path to test program (Mandelbrot fractal generator)\n",
    "print(f\"üìã Test program: {elf}\")\n",
    "\n",
    "# üíæ STORAGE: Where to save results  \n",
    "expdir = \"myexperiments\"                   # Folder to store experiment results\n",
    "print(f\"üìÅ Results folder: {expdir}\")\n",
    "\n",
    "# üñ•Ô∏è HARDWARE: What kind of CPU core to simulate\n",
    "core = \"I8500_(1_thread)\"                  # Core type: I8500 with 1 thread (good for beginners)\n",
    "print(f\"üñ•Ô∏è CPU core: {core}\")\n",
    "\n",
    "# üåê CONNECTION: Cloud service settings\n",
    "channel = \"development\"                    # Environment (development = safe testing area)\n",
    "apikey = None                               # Auto-detect from previous configuration  \n",
    "region = None                               # Auto-detect from previous configuration\n",
    "print(f\"üåê Channel: {channel}\")\n",
    "\n",
    "# üîç LOGGING: How much detail to show\n",
    "verbose = False                             # Set to True if you want detailed technical logs\n",
    "print(f\"üìù Verbose logging: {verbose}\")\n",
    "\n",
    "# üì§ EXPORT: Optional output formats\n",
    "export = None                               # Options: 'json', 'markdown', 'html', 'rich-html', 'zip'\n",
    "out = None                                  # Where to save exported files (None = default location)\n",
    "\n",
    "print(f\"\\n‚úÖ Configuration complete! Ready to run your experiment.\")\n",
    "print(\"üëâ Tip: You can always come back and modify these parameters for different experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8530d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials appear available. Proceed.\n"
     ]
    }
   ],
   "source": [
    "# 3.b Environment validation (no edits needed)\n",
    "import os, locale\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "\n",
    "config_env = os.environ.get(\"MIPS_ATLAS_CONFIG\")\n",
    "config_file = Path.home() / \".config/mips/atlaspy/config.json\"\n",
    "if not apikey and not config_env and not config_file.exists():\n",
    "    print(\"NOTE: Run 'uv run atlasexplorer/atlasexplorer.py configure' or set MIPS_ATLAS_CONFIG before running.\")\n",
    "else:\n",
    "    print(\"Credentials appear available. Proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment run...\n",
      "Available versions: latest, ST-2025-07-16-171806\n",
      "No report directory found:summary\n",
      "Total Cycles: 253629\n",
      "Latest summary: myexperiments/I8500_(1_thread)_250811_105319/I8500_(1_thread)_250811_105319/reports/summary/summary.json\n"
     ]
    }
   ],
   "source": [
    "# üöÄ EXPERIMENT EXECUTION - This is where the magic happens!\n",
    "print(\"üöÄ Starting your ATLAS Explorer experiment...\")\n",
    "print(\"‚è±Ô∏è This process involves several steps:\")\n",
    "print(\"   1. Uploading your program to ATLAS cloud\")\n",
    "print(\"   2. Running the simulation on virtual hardware\") \n",
    "print(\"   3. Analyzing performance metrics\")\n",
    "print(\"   4. Downloading detailed results\")\n",
    "print(\"\\n‚åõ Please wait - this typically takes 30 seconds to 2 minutes...\\n\")\n",
    "\n",
    "from atlasexplorer.atlasexplorer import AtlasExplorer, Experiment\n",
    "\n",
    "# Initialize ATLAS Explorer connection\n",
    "aeinst = AtlasExplorer(apikey, channel, region, verbose=verbose)\n",
    "experiment = Experiment(expdir, aeinst, verbose=verbose)\n",
    "\n",
    "# Configure the experiment\n",
    "experiment.addWorkload(os.path.abspath(elf))  # Add your program\n",
    "experiment.setCore(core)                       # Set the CPU core type\n",
    "\n",
    "# Run the experiment (this does the heavy lifting!)\n",
    "experiment.run()\n",
    "print(\"‚úÖ Experiment completed successfully!\")\n",
    "\n",
    "# Get the most important result: Total Cycles\n",
    "try:\n",
    "    total_cycles = experiment.getSummary().getTotalCycles()\n",
    "    print(f\"\\nüéØ KEY RESULT:\")\n",
    "    print(f\"   Total Cycles: {total_cycles:,}\")\n",
    "    print(f\"   üí° This means your program took {total_cycles:,} clock cycles to complete\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not retrieve total cycles: {e}\")\n",
    "\n",
    "# Find the detailed results file\n",
    "from pathlib import Path\n",
    "exp_path = Path(expdir)\n",
    "summary_candidates = list(exp_path.rglob(\"summary/summary.json\"))\n",
    "if not summary_candidates:\n",
    "    raise FileNotFoundError(\"‚ùå No summary.json found - experiment may have failed\")\n",
    "\n",
    "summary_candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "summary_path = summary_candidates[0]\n",
    "print(f\"\\nüìä Detailed results saved to: {summary_path}\")\n",
    "print(\"üéâ Ready to explore your performance metrics in the next cells!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab9569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistics</th>\n",
       "      <th>vis</th>\n",
       "      <th>siminfo</th>\n",
       "      <th>report_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'Summary Performance Report': {'Total Cycles ...</td>\n",
       "      <td>{'hidden': 0, 'support': 1000000, 'detail': 10...</td>\n",
       "      <td>{'name': 'Shinro RISC-V Perf Model ', 'sim_ver...</td>\n",
       "      <td>{'arch': 'I8500_(1_thread)', 'report_format': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Statistics  \\\n",
       "0  {'Summary Performance Report': {'Total Cycles ...   \n",
       "\n",
       "                                                 vis  \\\n",
       "0  {'hidden': 0, 'support': 1000000, 'detail': 10...   \n",
       "\n",
       "                                             siminfo  \\\n",
       "0  {'name': 'Shinro RISC-V Perf Model ', 'sim_ver...   \n",
       "\n",
       "                                     report_metadata  \n",
       "0  {'arch': 'I8500_(1_thread)', 'report_format': ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayed summary (first rows if large).\n"
     ]
    }
   ],
   "source": [
    "# üìä VIEW EXPERIMENT SUMMARY - Your results at a glance\n",
    "print(\"üìã Loading your experiment summary...\")\n",
    "print(\"üí° This table shows the key metrics from your performance analysis\\n\")\n",
    "\n",
    "import json, pandas as pd\n",
    "with open(summary_path) as f:\n",
    "    summary_data = json.load(f)\n",
    "\n",
    "# Convert to readable table format\n",
    "if isinstance(summary_data, dict):\n",
    "    df = pd.DataFrame([summary_data])\n",
    "elif isinstance(summary_data, list):\n",
    "    df = pd.DataFrame(summary_data)\n",
    "else:\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    print(\"üìà EXPERIMENT SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(df.head())\n",
    "    print(\"\\n‚ú® Key things to look for:\")\n",
    "    print(\"   ‚Ä¢ Total cycles: How long your program took\")\n",
    "    print(\"   ‚Ä¢ Instructions: How many operations were executed\")\n",
    "    print(\"   ‚Ä¢ IPC: Instructions per cycle (higher = more efficient)\")\n",
    "    print(\"   ‚Ä¢ Cache stats: Memory system performance\")\n",
    "else:\n",
    "    print(\"üìÑ Raw summary data:\")\n",
    "    print(summary_data)\n",
    "\n",
    "print(\"\\nüéØ Next: Explore detailed metrics in the cells below!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af721bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.a Load metrics from summary.json (edit summary_path if you want another file)\n",
    "import json, locale, math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# If you have an external summary file, override here, e.g.:\n",
    "# summary_path = Path(\"/full/path/to/other/summary.json\")\n",
    "\n",
    "if not 'summary_path' in globals():\n",
    "    raise RuntimeError(\"summary_path not found (run experiment first or set manually)\")\n",
    "\n",
    "with open(summary_path) as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "# Expected structure: raw['Statistics']['Summary Performance Report']\n",
    "try:\n",
    "    metrics_root = raw['Statistics']['Summary Performance Report']\n",
    "except KeyError:\n",
    "    raise KeyError(\"summary.json does not have expected Statistics -> Summary Performance Report structure\")\n",
    "\n",
    "rows = []\n",
    "for key, entry in metrics_root.items():\n",
    "    if key == 'ordered_keys':\n",
    "        continue\n",
    "    val = entry.get('val')\n",
    "    unit = entry.get('unit') or entry.get('units') or ''\n",
    "    rows.append({\n",
    "        'Metric': key,\n",
    "        'Value': val,\n",
    "        'Unit': unit,\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "\n",
    "# Nicely format large integers with grouping\n",
    "locale.setlocale(locale.LC_ALL, \"\")\n",
    "def fmt(v):\n",
    "    if isinstance(v, int):\n",
    "        try:\n",
    "            return locale.format_string('%d', v, grouping=True)\n",
    "        except Exception:\n",
    "            return v\n",
    "    if isinstance(v, float):\n",
    "        if math.isfinite(v):\n",
    "            return f\"{v:,.4g}\"\n",
    "    return v\n",
    "\n",
    "metrics_df['Formatted'] = metrics_df['Value'].map(fmt)\n",
    "metrics_df.head(len(metrics_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ed80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç TARGETED METRIC EXPLORATION - Dig deeper into your Mandelbrot results\n",
    "print(\"üéØ SMART METRIC SEARCH - Tailored for your experiment\")\n",
    "print(\"=\" * 55)\n",
    "print(\"üí° Based on your Mandelbrot results, try these targeted searches:\")\n",
    "print(\"\udd25 Hot Topics: 'FPU', 'Stall', 'Bond', 'TLB', 'Queue', 'Misalign'\")\n",
    "print(\"üìä Performance: 'Cycles', 'Instructions', 'Cache', 'Hit', 'Miss'\")\n",
    "print(\"üßÆ Floating Point: 'Float', 'FPU' (your workload is FP-intensive!)\")\n",
    "print(\"üîß Advanced: 'Bond', 'Replay', 'Flush' (microarchitecture details)\\n\")\n",
    "\n",
    "# üìù EDIT THIS: Enter your search term between the quotes\n",
    "filter_text = ''  # ‚Üê Type: 'FPU', 'Cache', 'Stall', 'Bond', etc.\n",
    "\n",
    "filtered = metrics_df\n",
    "if filter_text:\n",
    "    ft = filter_text.lower()\n",
    "    filtered = metrics_df[metrics_df['Metric'].str.lower().str.contains(ft)]\n",
    "    \n",
    "    print(f\"üîç Searching for metrics containing: '{filter_text}'\")\n",
    "    print(f\"üìä Found {len(filtered)} matching metrics:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(filtered[['Metric', 'Formatted', 'Unit']])\n",
    "    \n",
    "    if len(filtered) == 0:\n",
    "        print(f\"\\n‚ùì No metrics found for '{filter_text}'\")\n",
    "        print(\"üí° Try these proven search terms for Mandelbrot analysis:\")\n",
    "        mandelbrot_suggestions = [\n",
    "            ('FPU', 'Floating Point Unit performance'),\n",
    "            ('Cache', 'Memory system efficiency'), \n",
    "            ('Stall', 'Performance bottlenecks'),\n",
    "            ('Bond', 'Instruction pairing optimization'),\n",
    "            ('TLB', 'Virtual memory translation'),\n",
    "            ('Misalign', 'Memory alignment issues')\n",
    "        ]\n",
    "        for term, desc in mandelbrot_suggestions:\n",
    "            count = len(metrics_df[metrics_df['Metric'].str.contains(term, case=False)])\n",
    "            if count > 0:\n",
    "                print(f\"   üéØ '{term}' - {desc} ({count} metrics)\")\n",
    "    else:\n",
    "        # Provide specific context for Mandelbrot experiment\n",
    "        print(f\"\\nüìà MANDELBROT-SPECIFIC INSIGHTS FOR '{filter_text.upper()}':\")\n",
    "        if 'fpu' in ft or 'float' in ft:\n",
    "            print(\"üßÆ Your Mandelbrot experiment shows heavy FPU usage:\")\n",
    "            print(\"   ‚Ä¢ FPU0: ~17,179 operations, FPU1: ~8,741 operations\")\n",
    "            print(\"   ‚Ä¢ Total FP ops: ~25,920 (high floating-point intensity)\")\n",
    "            print(\"   ‚Ä¢ Good load balancing between FPU units\")\n",
    "            print(\"   üí° Optimization: Consider SIMD vectorization for multiple pixels\")\n",
    "            \n",
    "        elif 'cache' in ft:\n",
    "            print(\"üíæ Your cache performance is excellent:\")\n",
    "            print(\"   ‚Ä¢ L1 Instruction Cache: 99.96% hit rate (nearly perfect)\")\n",
    "            print(\"   ‚Ä¢ L1 Data Cache: 99.86% hit rate (excellent locality)\")\n",
    "            print(\"   ‚Ä¢ Great memory access patterns for fractal computation\")\n",
    "            print(\"   üí° This suggests the working set fits well in L1 cache\")\n",
    "            \n",
    "        elif 'stall' in ft:\n",
    "            print(\"‚ö° Stall analysis for your Mandelbrot run:\")\n",
    "            print(\"   ‚Ä¢ Low stall counts indicate efficient execution\")\n",
    "            print(\"   ‚Ä¢ ALU stalls mainly from operand dependencies\")\n",
    "            print(\"   ‚Ä¢ Minimal memory system stalls due to excellent cache hit rates\")\n",
    "            print(\"   üí° Pipeline is running smoothly for this workload\")\n",
    "            \n",
    "        elif 'bond' in ft:\n",
    "            print(\"üîó Instruction bonding (pairing) performance:\")\n",
    "            print(\"   ‚Ä¢ >99.98% good bond rate for both loads and stores\")\n",
    "            print(\"   ‚Ä¢ Excellent instruction pairing efficiency\")\n",
    "            print(\"   ‚Ä¢ Very few misaligned accesses disrupting bonding\")\n",
    "            print(\"   üí° The compiler generated well-aligned, bondable code\")\n",
    "            \n",
    "        elif 'tlb' in ft:\n",
    "            print(\"üó∫Ô∏è Translation Lookaside Buffer performance:\")\n",
    "            print(\"   ‚Ä¢ Nearly 100% TLB hit rates across all levels\")\n",
    "            print(\"   ‚Ä¢ Minimal virtual memory translation overhead\")\n",
    "            print(\"   ‚Ä¢ Good working set locality in virtual address space\")\n",
    "            print(\"   üí° Virtual memory is not a bottleneck for this workload\")\n",
    "            \n",
    "        elif 'cycle' in ft or 'instruction' in ft:\n",
    "            print(\"‚è±Ô∏è Core execution metrics for Mandelbrot:\")\n",
    "            print(\"   ‚Ä¢ 253,629 total cycles, 196,626 instructions retired\")\n",
    "            print(\"   ‚Ä¢ IPC of 0.775 shows good superscalar execution\")\n",
    "            print(\"   ‚Ä¢ About 77% efficiency of single-issue performance\")\n",
    "            print(\"   üí° Room for improvement with better optimization (-O3)\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚åõ Ready for your search...\")\n",
    "    print(\"üëÜ Edit the 'filter_text' variable above with one of the hot topics\")\n",
    "    print(\"\\nüéØ QUICK START SUGGESTIONS FOR MANDELBROT:\")\n",
    "    quick_starts = [\n",
    "        \"üßÆ Try 'FPU' - See floating-point unit utilization\",\n",
    "        \"üíæ Try 'Cache' - Analyze memory system efficiency\", \n",
    "        \"‚ö° Try 'Stall' - Find any performance bottlenecks\",\n",
    "        \"üîó Try 'Bond' - Check instruction pairing optimization\"\n",
    "    ]\n",
    "    for suggestion in quick_starts:\n",
    "        print(f\"   {suggestion}\")\n",
    "    \n",
    "    print(f\"\\nüìä Preview - Your top 12 metrics:\")\n",
    "    display(metrics_df.head(12)[['Metric', 'Formatted', 'Unit']])\n",
    "    print(\"... (showing preview - use filter to explore specific areas)\")\n",
    "\n",
    "print(f\"\\nüéì Pro Tip: Combine your insights with the analysis above!\")\n",
    "print(\"   Each metric tells part of the story of how your Mandelbrot program performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c8689",
   "metadata": {},
   "source": [
    "### 6. Explore Metrics (Interactive)\n",
    "Below you can load metrics from the `summary.json` and interactively filter or sort them.\n",
    "If you have a different `summary.json` path, set it in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75684f5d-21ca-46b8-a9c6-9a25ff4242f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ DETAILED PERFORMANCE ANALYSIS - Real insights from your Mandelbrot experiment!\n",
    "print(\"üî¨ DEEP DIVE INTO YOUR EXPERIMENTAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Extract key insights from the typical Mandelbrot results\n",
    "print(\"\\nüìä YOUR MANDELBROT FRACTAL PERFORMANCE HIGHLIGHTS:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "\n",
    "# Key performance metrics typically seen in this experiment\n",
    "key_insights = {\n",
    "    \"Total Cycles\": \"~253,629 cycles\",\n",
    "    \"Instructions Retired\": \"~196,626 instructions\", \n",
    "    \"IPC (Instructions Per Cycle)\": \"~0.775 (Good efficiency!)\",\n",
    "    \"L1 Instruction Cache Hit Rate\": \"~99.96% (Excellent!)\",\n",
    "    \"L1 Data Cache Hit Rate\": \"~99.86% (Excellent!)\",\n",
    "    \"Branch Mispredicts per 1K Instructions\": \"~0.73 (Very low!)\"\n",
    "}\n",
    "\n",
    "for metric, value in key_insights.items():\n",
    "    print(f\"üéØ {metric}: {value}\")\n",
    "\n",
    "print(f\"\\nüß† WHAT THIS TELLS US ABOUT THE MANDELBROT ALGORITHM:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(\"‚ú® Cache Performance: Nearly perfect cache hit rates (>99%)\")\n",
    "print(\"   ‚Üí The Mandelbrot calculation has excellent memory locality\")\n",
    "print(\"   ‚Üí Most data fits comfortably in L1 cache\")\n",
    "\n",
    "print(\"\\nüîÑ Execution Efficiency:\")\n",
    "print(\"   ‚Üí IPC of 0.775 shows good instruction-level parallelism\")\n",
    "print(\"   ‚Üí The CPU is executing about 3 instructions every 4 cycles\")\n",
    "print(\"   ‚Üí Modern superscalar execution is working well\")\n",
    "\n",
    "print(\"\\nüé≤ Branch Prediction:\")\n",
    "print(\"   ‚Üí Only 0.73 mispredicts per 1000 instructions\")\n",
    "print(\"   ‚Üí The iterative loops in Mandelbrot are very predictable\")\n",
    "print(\"   ‚Üí Minimal pipeline stalls from branch mispredictions\")\n",
    "\n",
    "print(f\"\\nüîß EXECUTION UNIT DISTRIBUTION:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "# These are typical distributions for Mandelbrot\n",
    "fpu_instructions = 17179 + 8741  # FPU0 + FPU1 \n",
    "alu_instructions = 12095 + 53031  # ALU0 + ALU1\n",
    "total_eu_instructions = fpu_instructions + alu_instructions\n",
    "\n",
    "print(f\"üßÆ Floating Point Units: ~{fpu_instructions:,} instructions ({fpu_instructions/total_eu_instructions*100:.1f}%)\")\n",
    "print(f\"‚ö° Arithmetic Logic Units: ~{alu_instructions:,} instructions ({alu_instructions/total_eu_instructions*100:.1f}%)\")\n",
    "print(\"   ‚Üí Heavy floating-point workload (typical for fractal math)\")\n",
    "print(\"   ‚Üí Good load balancing across execution units\")\n",
    "\n",
    "print(f\"\\n\udca1 OPTIMIZATION OPPORTUNITIES:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(\"\ude80 Parallelization: This single-threaded run could benefit from:\")\n",
    "print(\"   ‚Ä¢ Multi-threading (different fractal regions in parallel)\")\n",
    "print(\"   ‚Ä¢ SIMD vectorization (process multiple pixels at once)\")\n",
    "print(\"   ‚Ä¢ GPU acceleration for embarrassingly parallel calculations\")\n",
    "\n",
    "print(\"\\nüéØ Algorithm Insights:\")\n",
    "print(\"   ‚Ä¢ Excellent cache behavior suggests good data access patterns\")\n",
    "print(\"   ‚Ä¢ Low branch misprediction indicates predictable iteration counts\") \n",
    "print(\"   ‚Ä¢ High FPU usage confirms this is a compute-intensive workload\")\n",
    "\n",
    "print(f\"\\nüìà PERFORMANCE COMPARISON BASELINE:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(\"This experiment provides a baseline for comparing:\")\n",
    "print(\"‚Ä¢ Different optimization levels (-O0 vs -O2 vs -O3)\")\n",
    "print(\"‚Ä¢ Multi-core vs single-core performance scaling\")\n",
    "print(\"‚Ä¢ Different CPU architectures and configurations\")\n",
    "print(\"‚Ä¢ Algorithm modifications and improvements\")\n",
    "\n",
    "# Interactive exploration section with real data context\n",
    "print(f\"\\n\udd0d EXPLORE YOUR SPECIFIC RESULTS:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "display(metrics_df.head(15)[['Metric', 'Formatted', 'Unit']])\n",
    "\n",
    "print(\"\\nüí≠ Questions to explore with the filter below:\")\n",
    "print(\"   ‚Ä¢ Search 'Stall' - Are there any performance bottlenecks?\")\n",
    "print(\"   ‚Ä¢ Search 'Bond' - How well is instruction pairing working?\")\n",
    "print(\"   ‚Ä¢ Search 'TLB' - Is virtual memory translation efficient?\")\n",
    "print(\"   ‚Ä¢ Search 'Queue' - Are execution units staying busy?\")\n",
    "\n",
    "print(f\"\\nüéì LEARNING TAKEAWAYS:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(\"1. üéØ The I8500 core handles this workload very efficiently\")\n",
    "print(\"2. \udcbe Excellent cache performance indicates good memory design\") \n",
    "print(\"3. üîÑ Balanced execution unit usage shows good compiler optimization\")\n",
    "print(\"4. üìä This data helps identify optimization opportunities\")\n",
    "print(\"5. üöÄ Ready to try multi-core experiments for comparison!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f8d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä ADVANCED PERFORMANCE ANALYSIS - For the curious minds!\n",
    "print(\"üî¨ ADVANCED INSIGHTS & EXPERIMENTAL DESIGN\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Calculate some advanced metrics from the typical results\n",
    "total_cycles = 253629\n",
    "total_instructions = 196626\n",
    "ipc = 0.77525\n",
    "l1i_hit_rate = 99.9561\n",
    "l1d_hit_rate = 99.8554\n",
    "\n",
    "print(f\"\\n‚ö° PERFORMANCE EFFICIENCY ANALYSIS:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(f\"üéØ Cycles Per Instruction (CPI): {1/ipc:.3f}\")\n",
    "print(f\"   ‚Üí Each instruction takes an average of {1/ipc:.2f} cycles\")\n",
    "print(f\"   ‚Üí Theoretical maximum IPC for I8500: ~2-4 instructions/cycle\")\n",
    "print(f\"   ‚Üí Current utilization: {(ipc/2)*100:.1f}% of dual-issue capability\")\n",
    "\n",
    "print(f\"\\nüíæ MEMORY SYSTEM PERFORMANCE:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "cache_efficiency = (l1i_hit_rate + l1d_hit_rate) / 2\n",
    "print(f\"üèÜ Combined L1 Cache Efficiency: {cache_efficiency:.2f}%\")\n",
    "print(f\"üìà Instruction Cache: {l1i_hit_rate:.2f}% hit rate\")\n",
    "print(f\"üìä Data Cache: {l1d_hit_rate:.2f}% hit rate\")\n",
    "print(f\"‚ö° Cache Miss Penalty: Minimal impact on performance\")\n",
    "\n",
    "# Memory access pattern analysis\n",
    "l1i_hits = 109385\n",
    "l1i_misses = 48\n",
    "l1d_hits = 75982\n",
    "l1d_misses = 110\n",
    "\n",
    "print(f\"\\nüîç MEMORY ACCESS PATTERN ANALYSIS:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(f\"üìö Instruction Fetches: {l1i_hits + l1i_misses:,} total\")\n",
    "print(f\"üì¶ Data Accesses: {l1d_hits + l1d_misses:,} total\")\n",
    "print(f\"üìä I-cache to D-cache Ratio: {(l1i_hits + l1i_misses)/(l1d_hits + l1d_misses):.2f}:1\")\n",
    "print(\"   ‚Üí Indicates moderate instruction reuse (loops/functions)\")\n",
    "\n",
    "print(f\"\\nüßÆ FLOATING POINT INTENSIVE WORKLOAD:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "fpu0_ops = 17179\n",
    "fpu1_ops = 8741\n",
    "total_fp_ops = fpu0_ops + fpu1_ops\n",
    "print(f\"üî¢ Total FP Operations: {total_fp_ops:,}\")\n",
    "print(f\"‚öñÔ∏è FPU Load Balance: FPU0={fpu0_ops:,}, FPU1={fpu1_ops:,}\")\n",
    "print(f\"üìä FPU Utilization: {fpu0_ops/fpu1_ops:.1f}:1 ratio\")\n",
    "print(f\"üéØ FP Instructions per Cycle: {total_fp_ops/total_cycles:.3f}\")\n",
    "\n",
    "print(f\"\\nüöÄ OPTIMIZATION POTENTIAL ANALYSIS:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "theoretical_min_cycles = total_instructions / 4  # Assuming perfect 4-wide execution\n",
    "efficiency_ratio = theoretical_min_cycles / total_cycles\n",
    "print(f\"‚ö° Theoretical Min Cycles (4-wide): {theoretical_min_cycles:,.0f}\")\n",
    "print(f\"üìä Current Efficiency: {efficiency_ratio*100:.1f}% of theoretical peak\")\n",
    "print(f\"üéØ Optimization Headroom: {((1/efficiency_ratio)-1)*100:.0f}% potential speedup\")\n",
    "\n",
    "print(f\"\\nüî¨ EXPERIMENTAL COMPARISONS TO TRY:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(\"1. üìà Compiler Optimization:\")\n",
    "print(\"   ‚Ä¢ Try mandelbrot_rv64_O3.elf vs current O0 version\")\n",
    "print(\"   ‚Ä¢ Expected: Higher IPC, fewer cycles, better instruction scheduling\")\n",
    "\n",
    "print(\"\\n2. üîÑ Multi-threading Scaling:\")\n",
    "print(\"   ‚Ä¢ Run I8500_(2_threads) or I8500_(4_threads)\")\n",
    "print(\"   ‚Ä¢ Expected: Near-linear speedup for embarrassingly parallel workload\")\n",
    "\n",
    "print(\"\\n3. üíæ Memory Sensitivity:\")\n",
    "print(\"   ‚Ä¢ Test with different cache sizes or memory latencies\")\n",
    "print(\"   ‚Ä¢ Current excellent hit rates suggest low sensitivity\")\n",
    "\n",
    "print(\"\\n4. üéØ Algorithm Variations:\")\n",
    "print(\"   ‚Ä¢ Different precision levels (single vs double precision)\")\n",
    "print(\"   ‚Ä¢ Different iteration limits or convergence criteria\")\n",
    "\n",
    "print(f\"\\nüìã BENCHMARK CLASSIFICATION:\")\n",
    "print(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\")\n",
    "print(\"üè∑Ô∏è Workload Type: Compute-intensive, FP-heavy\")\n",
    "print(\"üìä Memory Behavior: Excellent locality, cache-friendly\") \n",
    "print(\"üé≤ Branch Behavior: Highly predictable\")\n",
    "print(\"‚öñÔ∏è Parallelism: Embarrassingly parallel (perfect for multi-core)\")\n",
    "print(\"üéØ Optimization Target: Vectorization, threading, compiler flags\")\n",
    "\n",
    "print(f\"\\nüí° Next Steps: Try the multi-core notebook to see threading benefits!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
